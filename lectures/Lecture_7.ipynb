{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbor classifier\n",
    "\n",
    "finds known data $x_i$ which is closest to new data $x$\n",
    "\n",
    "returns label of $x_i$, $y_i$\n",
    "\n",
    "### to find distance:\n",
    "\n",
    "- default = euclidean distance (line of sight)\n",
    "- $||u - v||_2 = (\\sum^d_{i=1}(u_i - v_i)^2)^{\\frac{1}{2}}$ \n",
    "- can use $l_p$ for $p \\in [1,\\infty]$\n",
    "- $||u - v||_p = (\\sum^d_{i=1}(u_i - v_i)^p)^{\\frac{1}{p}}$ \n",
    "\n",
    "for other types of data we can use whatever way\n",
    "\n",
    "### k-nearest neighbor\n",
    "\n",
    "- finds k known data pairs $x_i$ and $y_i$\n",
    "- returns a majority vote of labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Classifier\n",
    "\n",
    "Bayes classifier most accurate.\n",
    "\n",
    "predicted class = most likely class\n",
    "\n",
    "$f^\\star(x) := \\arg \\max_{y∈Y}P(Y = y|X = x)$\n",
    "\n",
    "$f^\\star(x) := \\arg \\max_{y∈Y}P(Y = y)P(X = x|Y = y)$\n",
    "\n",
    "class prior = $P(Y = y)$\n",
    "\n",
    "class conditional distribution of X = $P(X = x|Y = y)$\n",
    "\n",
    "If X = continuous-valued random variable:\n",
    "- replace $P(X = x|Y = y)$ with class conditional density $p(x|Y = y)$\n",
    "\n",
    "Has smallest prediction error of all classifiers\n",
    "\n",
    "We dont know distribution P\n",
    "\n",
    "we can use data to find $P(Y = y)$ and $P(X = x|Y = y)$\n",
    "\n",
    "### Approximation using MLE\n",
    "\n",
    "$X = \\mathbb{R}^d$ and $Y = \\{1, . . . , K\\}$\n",
    "\n",
    "Prior: $\\hat{\\pi}_y = \\frac{1}{n}P^n_{i=1} \\mathbb{1}(y_i = y)$\n",
    "- this is simply the probability of this label in the whole data set\n",
    "\n",
    "Class conditional density: Choose $p(x|Y = y) = N(x|\\mu_y, \\Sigma_y)$\n",
    "\n",
    "$\\hat{\\mu}_y = \\frac{1}{n_y}\\sum^n_{i=1}\\mathbb{1}(y_i = y)x_i$\n",
    "- mean of x data points of given class\n",
    "\n",
    "$\\hat{\\Sigma}_y = \\frac{1}{n_y}\\sum^n_{i=1}\\mathbb{1}(y_i = y)(x_i - \\hat{\\mu}_y)(x_i - \\hat{\\mu}_y)^T$\n",
    "- variance of x data points of given class\n",
    "\n",
    "Plug-in classifier:\n",
    "\n",
    "$\\hat{f}(x) = \\arg \\max_{y\\in Y}\\hat{\\pi}_y|\\hat{\\Sigma}_y|^{-\\frac{1}{2}} \\exp\\left\\{-\\frac{1}{2}(x - \\hat{\\mu}_y)^T\\hat{\\Sigma}^{−1}_y(x - \\hat{\\mu}_y)\\right\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "assumes conditional independence of dimension of x from y\n",
    "\n",
    "$p(X = x|Y = y) = \\prod^d_{j=1}p_j(x(j)|Y = y)$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
