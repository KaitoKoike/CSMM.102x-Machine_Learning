{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "map the features of the data to a higher dimensionality\n",
    "\n",
    "$x \\in \\mathbb{R}^d$\n",
    "\n",
    "$\\phi(x) \\in \\mathbb{R}^D$\n",
    "\n",
    "where D > d\n",
    "\n",
    "eg. polynomial regression:\n",
    "- $\\phi(x) = (x, x^2, ..., x^p)$\n",
    "eg. something:\n",
    "- $\\phi(x) = (x, \\mathbb{1}(x>a), \\cos x)$\n",
    "\n",
    "higher dimensionality can meen its linear in the inputs\n",
    "\n",
    "there is a weight for each feature\n",
    "\n",
    "### How to pick expansion\n",
    "\n",
    "choose all possible features and use this function\n",
    "\n",
    "$w_{\\ell_1} = \\arg \\min_w\\sum^n_{i=1}f(y_i, \\phi(x_i), w) + \\lambda|w|_1$\n",
    "\n",
    "this will encourage sparsity of w using an $\\ell_1$ penalty\n",
    "\n",
    "But normally we only need:\n",
    "\n",
    "$\\phi(x_i)^T\\phi(x_j) \\equiv K(x_i,x_j)$\n",
    "- this is called a kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Definition\n",
    "\n",
    "$K(\\cdot,\\cdot)$: $\\mathbb{R}^d \\times \\mathbb{R}^d \\to \\mathbb{R}$\n",
    "- symetric function\n",
    "\n",
    "$x_1,...,x_n \\in \\mathbb{R}^d$\n",
    "\n",
    "$n\\times n$ matrix, K\n",
    "\n",
    "$K_{ij} = K(x_i,x_j)$\n",
    "\n",
    "K is positive semidefinite (this satifies the properties of a covariance matrix)\n",
    "\n",
    "This means theres a function for the mapping:\n",
    "\n",
    "$\\phi:\\mathbb{R}^d \\to \\mathbb{R}^D$ so that\n",
    "\n",
    "$K(x_i,x_j) = \\phi(x_i)^T\\phi(x_j)$\n",
    "\n",
    "sometimes we dont define $\\phi$ but instead jump straight to $K$\n",
    "\n",
    "### Gaussian Kernel (Radial Basis Function RBF)\n",
    "\n",
    "$K(x, x\\prime) = a\\exp\\left\\{-\\frac{1}{b}||x-x\\prime||^2\\right\\}$\n",
    "- things close have a larger value\n",
    "- the mapping is infinite dimensional (continous function rather than vector)\n",
    "- $K(x, x\\prime) = \\int\\phi_t(x)\\phi_t(x\\prime)dt$\n",
    "- like gaussian on $x$ with $x\\prime$ as mean or opposite\n",
    "\n",
    "### Another Kernel\n",
    "\n",
    "$\\phi(x) = (1,\\sqrt{2}x_1,..., \\sqrt{2}x_d, x^2_1,..., x^2_d,..., \\sqrt{2}x_ix_j,...)$\n",
    "\n",
    "$\\phi(x)^T\\phi(x\\prime) = K(x, x\\prime) = (1 + x^Tx\\prime)^2$\n",
    "\n",
    "we can show: $K(x, x\\prime) = (1 + x^Tx\\prime)^b$, for $b > 0$ is a kernel as well\n",
    "\n",
    "### Kernel arithmetic\n",
    "\n",
    "kernels can be a product of other kernels like:\n",
    "\n",
    "$K(x, x\\prime) = K_1(x, x\\prime)K_2(x, x\\prime)$\n",
    "\n",
    "$K(x, x\\prime) = K_1(x, x\\prime) + K_2(x, x\\prime)$\n",
    "\n",
    "$K(x, x\\prime) = \\exp\\{K_1(x, x\\prime)\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Kernelized perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$y_0 = sign(\\sum_{i\\in M}y_i\\phi(x_0)^T\\phi(x_i))$\n",
    "\n",
    "$y_0 = sign(\\sum_{i\\in M}y_iK(x_0,x_i))$\n",
    "\n",
    "using rbf kernel (with a =1)\n",
    "\n",
    "$y_0 = sign(\\sum_{i\\in M}y_ie^{-\\frac{1}{b}||x_0-x_i||^2})$\n",
    "- we dont actually have to calculate $\\phi(.)$\n",
    "- this is like voting with the closer values weighted nearer to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KERNELIZED BAYESIAN LINEAR REGRESSION\n",
    "\n",
    "##### Setup:\n",
    "\n",
    "$y \\sim N(Xw, o^2I)$\n",
    "\n",
    "$w \\sim N(0, \\lambda^{-1}I)$\n",
    "\n",
    "##### Marginalising:\n",
    "\n",
    "Integrating out w\n",
    "\n",
    "$p(y|X) = \\int p(y|X, w)p(w)dw = N(0, \\sigma^2I + \\lambda^{-1}XX^T)$\n",
    "\n",
    "##### Kernelization\n",
    "\n",
    "- $(XX^T)_{ij} = x^T_ix_j$\n",
    "- replace $x$ with $\\phi(x)$\n",
    "- $(\\phi(X)\\phi(X)^T)_{ij} = K(x_i, x_j)$\n",
    "\n",
    "$p(y|X) = \\int p(y|X, w)p(w)dw = N(0, \\sigma^2I + \\lambda^{âˆ’1}K)$\n",
    "\n",
    "#### Gaussian Process\n",
    "\n",
    "- $f(x) \\in \\mathbb{R}$ and $x \\in \\mathbb{R}^d$\n",
    "- $K(x, x\\prime)$ between two points $x$ and $x\\prime$\n",
    "- $f(x)$ is a Gaussian process and $y(x)$ the noise-added process if\n",
    "\n",
    "$y|f \\sim N(f,\\sigma^2I)$,  $f\\sim N(0, K) \\Leftrightarrow y \\sim N(0, \\sigma^2I + K)$\n",
    "- where $y = (y_1,..., y_n)^T$ and $K$ is $n \\times n$ with $K_{ij} = K(x_i, x_j)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
